%!TEX root = appunti.tex
%!TEX encoding = UTF-8 Unicode
\chapter{Distribuzioni discrete}
\begin{definition}[Distribuzione discreta]\label{def:distribuzione_discreta}
  Una distribuzione statistica le cui variabili possono avere solo valori discreti.

  Dunque, un numero aleatorio \( X \) si dice con distribuzione discreta se la cardinalità di \( I(X) \) è finita o numerabile.
\end{definition}
\begin{definition}[Distribuzione di probabilità]\label{def:distribuzione_di_probabilita}
  La funzione che descrive la probabilità che un certo valore si verifichi.
  \marginnote{La distribuzione di probabilità viene anche detta ``funzione di densità di probabilità''.}

  Se consideriamo \( X \) una variabile aleatoria con distribuzione discreta, la sua distribuzione di probabilità sarà data da
  \[ \pr(X = x_i) = p(x_i) \text{ con } x_i \in I(X) \]
  dove
  \[ \sum_{x_i \in I(X)} \pr(X = x_i) = 1 \]
\end{definition}

\begin{definition}[Schema di Bernoulli]\label{def:schema_bernoulli}
  Una successione \( (E_i)_{i \in \mathbb{N}} \) di eventi stocasticamente indipendenti ed equiprobabili, ovvero tali per cui vale che
  \[ \pr(E_i) = p, ~ \forall i \in \mathbb{N} \]
\end{definition}

\section{Distribuzione binomiale} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_binomiale}
  \caption{Distribuzione binomiale}
\end{figure*}

\begin{definition}[Distribuzione binomiale]
  \label{def:distribuzione_binomiale}
  La distribuzione discreta di probabilità del numero di successi in una sequenza di \( n \) eventi indipendenti, dove ognuno di essi ha successo con probabilità \( p \).
  \footnote{e fallimento con probabilità \( (1-p) \). Questo tipo di esperimenti di successo/fallimento si chiamano prove di Bernoulli o schema di Bernoulli, vedi definizione \ref{def:schema_bernoulli}.}

  \[ \mathcal{B}(n, p) \equiv \pr(X = k) = \binom{n}{k} p^k (1-p)^{n-k} \]
\end{definition}

\begin{proof}
  Dato uno schema di Bernoulli \( (E_i)_{i \in \mathbb{N}} \) con \( \pr(E_i) = p \),
  \[ X = (E_1 + \ldots + E_n) \]
  è il numero di successi su \( n \) prove dove, ovviamente,
  \[ I(X) = \{0, \ldots, n\} \]
  
  La distribuzione di probabilità dunque è, tramite i costituenti:
  \[ \pr(X = k) = \sum_{Q \subset (X = k)} \pr(Q) \]
  ovvero dobbiamo sommare tutte le probabilità dei costituenti del primo tipo dell'evento \( (X = k) \), come, ad esempio
  \[ Q = E_1 \cdots E_k \tilde{E}_{k+1} \cdots \tilde{E}_n \]
  che rappresenta l'evento in cui i \( k \) successi si sono ottenuti con le prime \( k \) prove.
  Analogamente ogni altro costituente di \( (X = k) \) conterrà \( k \) eventi che si sono verificati e \( n-k \) che non si sono verificati.
  Siccome tutti gli eventi sono indipendenti ed equamente distribuiti, ogni costituente \( Q \) ha la stessa probabilità, pari a
  \[ \pr(Q) = p^k (1-p)^{n-k} \]
  
  Dunque per avere \( \pr(X = k) \), basta contare i costituenti.
  Essi sono uguali al numero di modi di scegliere i \( k \) eventi che si verificano sugli \( n \) totali. Si ottiene quindi
  \[ \pr(X = k) = \binom{n}{k} p^k (1-p)^{n-k} \]

  Si dice dunque che \( X \) ha distribuzione binomiale \( \mathcal{B}(n, p) \) dove \( n \) è il numero degli eventi e \( p \) la probabilità di ognuno.
\end{proof}

\begin{proposition}[Previsione di \( X \) con distribuzione binomiale]
  \marginnote{vedi definizione \ref{def:schema_bernoulli}}
  \begin{align*}
    \pr(X) &= \pr(E_1 + \ldots + E_n) \\
    &= \sum_{i=1}^n \pr(E_i) \\
    &= np
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di un evento di Bernoulli]
  \marginnote{\( \pr(E_i^2) = \pr(E_i) \) perché \( 0^2 = 0 \) e \( 1^2 = 1 \).}
  \begin{align*}
    \var(E_i) &= \pr(E_i^2) - \pr(E_i)^2 \\
    &= \pr(E_i) - \pr(E_i)^2 \\
    &= p - p^2 \\
    &= p (1 - p)
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di \( X \) con distribuzione binomiale]
  \begin{align*}
    \var(X) &= \var(E_1 + \ldots + E_n) \\
    &= \sum_{i = 1}^n \var(E_i) \\
    &= \sum_{i = 1}^n p (1 - p) \\
    &= n p (1 - p)
  \end{align*}
\end{proposition}

% TODO 'moda' della distribuzione

% section distribuzione_binomiale (end)

\section{Distribuzione ipergeometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_ipergeometrica}
  \caption{Distribuzione ipergeometrica}
\end{figure*}

\begin{definition}[Distribuzione ipergeometrica]
  \label{def:distribuzione_ipergeometrica}
  \marginnote{La distribuzione ipergeometrica è simile alla distribuzione binomiale, che però descrive il numero di successi per \( n \) eventi \emph{indipendenti}, vedi \ref{def:distribuzione_binomiale}.}
  La distribuzione discreta di probabilità che descrive il numero di successi in una sequenza di  \( n \) eventi dipendenti, date \( H \) possibilità di successo su \( N \) possibilità totali.

  \[ \mathcal{H}(n, H, N) \equiv \pr(X = i) = \frac{\binom{H}{i} \binom{N-H}{n-i}}{\binom{N}{n}} \]
\end{definition}

% TODO vincoli

\begin{proof}
  Consideriamo \( H \) possibilità di successo ed \( N - H \) possibilità di fallimento, su un totale di \( N \).
  Facciamo \( n \) prove e sia
  \[ E_i = (\text{successo all'}i\text{-esima prova}) \]
  Sia \( X \) il numero aleatorio che conta il numero di successi:
  \[ X = \sum_{i = 1}^n E_i \]

  Allora la probabilità di avere \( i \) successi è
  \marginnote{Il numero di casi possibili equivale a tutti i modi di effettuare \( n \) selezioni su \( N \) possibilità totali senza ripetizione e senza tener conto dell'ordine, ovvero ad una combinazione semplice, vedi definizione \ref{def:combinazione_semplice}.

  Otteniamo analogamente i casi possibili, tenendo conto che per ottenere \( i \) successi dobbiamo ottenere \( n - i \) fallimenti.}
  \begin{align*}
    \pr(X = i) &= \frac{\text{\# casi favorevoli}}{\text{\# casi possibili}} \\
    &= \frac{(\text{\# modi per }i\text{ successi})(\text{\# modi per }n - i\text{ fallimenti})}{\text{\# casi possibili}} \\
    &= \frac{\binom{H}{i} \binom{N-H}{n-i}}{\binom{N}{n}}
  \end{align*}

  Si dice dunque che \( X \) possiede distribuzione ipergeometrica.
\end{proof}

\begin{proposition}[Previsione di \( X \) con distribuzione ipergeometrica]
  \begin{align*}
    \pr(X) &= \sum_{i=1}^n \pr(E_i) \\
    &= \sum_{i=1}^n \frac{H}{N} \\
    &= n \frac{H}{N}
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di \( X \) con distribuzione ipergeometrica]
  \begin{align*} % TODO semplificare sta bestia
    \var(X) &= \var(E_1 + \ldots + E_n) \\
    &= \sum_{i = 1}^n \var(E_i) + \sum_{i,j ~ i < j} \cov(E_i, E_j) \\ % DOUBT non ho la più pallida idea del perché
    &= n \frac{H}{N} \left( 1 - \frac{H}{N} \right) + D_2^n \frac{H}{N^2} \frac{H - N}{N - 1} \\
    &= n \frac{N - n}{N - 1} \frac{H}{N} (1 - \frac{H}{N})
  \end{align*}
\end{proposition}

% section distribuzione_ipergeometrica (end)

\section{Distribuzione congiunta e marginale} % (fold)
\begin{definition}[Distribuzione congiunta]
  \label{def:distribuzione_congiunta}
  La funzione che definisce la probabilità di eventi definiti in termini di due numeri aleatori \( X \) ed \( Y \):
  \[ p(x,y) \equiv \pr(X = x, Y = y) \]
  dove:
  \[ (x,y) \in I(X,Y) \]
\end{definition}
È possibile rappresentare l'insieme dei valori che può assumere la funzione tramite la matrice:
\[
\begin{pmatrix}
  p(x_1, y_1) & \dots & p(x_1, y_n) \\
  \vdots & \ddots & \vdots \\
  p(x_m, y_1) & \dots & p(x_m, y_n)
\end{pmatrix}
\]

Inoltre:
\[ \sum_x \sum_y p(x,y) = 1 \]

\begin{definition}[Distribuzione marginale]
  \label{def:distribuzione_marginale}
  Dato un numero aleatorio \( X \) è la funzione
  \[ p(x) \equiv \pr(X = x) \]

  Conoscendo la distribuzione congiunta possiamo determinare la marginale, perché
  \begin{align*}
    p_1(x) &= \pr(X = x) \\
    &= \sum_{j = 1}^n \pr(X = x, Y = y_j) \\
    &= \sum_{j = 1}^n p(x, y_j)
  \end{align*}
  o analogamente per \( y \)
  \begin{align*}
    p_2(y) &= \pr(Y = y) \\
    &= \sum_{i = 1}^m \pr(X = x_i, Y = y) \\
    &= \sum_{i = 1}^m p(x_i, y)
  \end{align*}
\end{definition}

\begin{definition}[Indipendenza stocastica tramite la distribuzioni marginale]
  Due numeri aleatori \( X \) ed \( Y \) sono stocasticamente indipendenti se
  \[ \forall i,j ~~ p(x_i, y_j) = p_1(x_i) p_2(y_j) \]
\end{definition}
% TODO gli appunti finiscono qui, ma sul libro a questo punto c'è altra roba...

% section distribuzione_congiunta_e_marginale (end)

\section{Distribuzione geometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_geometrica}
  \caption{Distribuzione geometrica}
\end{figure*}

\begin{definition}[Distribuzione geometrica]
  \label{def:distribuzione_geometrica}
  La distribuzione discreta della probabilità di ottenere il primo successo all'istante \( i \) in una serie di prove.
\end{definition}

Dato uno schema di Bernoulli \( E_i \) ed un numero aleatorio \( T \) che rappresenta l'istante del primo successo in una serie di prove, ovvero \( T = \inf\{ n | E_n = 1 \} \).
\[ I(T) = \mathbb{N} \setminus \{ 0 \} \]
\[ (T = i) = \tilde{E}_1 \cdots \tilde{E}_{i-1} E_i \]

La distribuzione discreta di probabilità è
\begin{align*}
  \pr(T = i) &= \pr(\tilde{E}_1 \cdots \tilde{E}_{i-1} E_i) \\
  &= \pr(\tilde{E}_1) \cdots \pr(\tilde{E}_{i-1}) \pr(E_i) \\
  &= (1-p)^{i-1} p
\end{align*}

Si dice che \( T \) ha distribuzione geometrica di parametro \( p \).
Utilizzando la somma della serie geometrica, si verifica che
\begin{align*}
  \sum_{i=1}^{+ \infty} \pr(T = i) &= \sum_{i=1}^{+ \infty} (1-p)^{i-1} p \\
  &= p \sum_{i=1}^{+ \infty} (1-p)^{i-1}  \\
  &= p \frac{1}{1-(1-p)} \\
  &= 1
\end{align*}

% DOUBT come si chiama questo teorema?
\marginnote{Per ottenere questi ultimi due risultati abbiamo usato la serie notevole
  \begin{align*}
    \sum_{i=1}^{+ \infty} i x^{i-1} &= \sum_{i=1}^{+ \infty} \frac{d}{dx}[x^i] \\
    &= \frac{d}{dx} (\sum_{i=0}^{+ \infty} x^i) \\
    &= \frac{d}{dx} (\frac{1}{1-x}) \\
    &= \frac{1}{(1-x)^2}
  \end{align*}
}

\newthought{Possiamo dunque calcolare la previsione di \( T \)}:
\begin{align*}
  \pr(T) &= \sum_{i=1}^{+ \infty} i \pr(T = i) \\
  &= \sum_{i=1}^{+ \infty} i (i - p)^{i-1} p \\
  &= p \sum_{i=1}^{+ \infty} i (i - p)^{i-1} \\
  &= p \frac{1}{p^2} \\
  &= \frac{1}{p}
\end{align*}

% TODO dimostrare perché \pr(T^2) = \frac{2-p}{p^2}
\newthought{E, dato \( \pr(T^2) = \frac{2-p}{p^2} \), la sua varianza}:
\begin{align*}
  \var(T) &= \pr(T^2) - \pr(T)^2 \\
  &= \frac{2-p}{p^2} - \frac{1}{p^2} \\
  &= \frac{1-p}{p^2}
\end{align*}

% section distribuzione_geometrica (end)

\section{Distribuzione di Poisson} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_di_poisson}
  \caption{Distribuzione di Poisson}
\end{figure*}

\begin{definition}[Distribuzione di Poisson]
  \label{def:distribuzione_di_poisson}
  La distribuzione discreta della probabilità di ottenere \( i \) successi in un intervallo di tempo fissato,
  se questi eventi si verificano con una frequenza media nota e indipendentemente dal tempo passato dall'ultimo evento.

  È uguale a
  \[ Pois(\lambda) \equiv \pr(X = i) = \frac{\lambda^i}{i!} e^{- \lambda} \]
  dove \( \lambda \) è un numero reale positivo, pari al numero atteso di eventi che si verificano durante l'intervallo di tempo e \( I(X) = \mathbb{N} \).
\end{definition}

\begin{proposition}[Previsione di \( X \) con distribuzione di Poisson]
  \label{pro:previsione_distribuzione_di_poisson}
  \marginnote{Utilizziamo la serie notevole \[ \sum_{k=0}^{+ \infty} \frac{x^k}{k!} = e^x \] e la definizione di fattoriale \[ i! = i(i-1)! \]}
  \begin{align*}
    \pr(X) &= \sum_{i=0}^{+ \infty} i \pr(X = i) \\
    &= \sum_{i=0}^{+ \infty} i \frac{\lambda^i}{i!} e^{- \lambda} \\
    &= e^{- \lambda} \sum_{i=0}^{+ \infty} \frac{\lambda^i}{(i-1)!} \\
    &= \lambda e^{- \lambda} \sum_{i=1}^{+ \infty} \frac{\lambda^{i-1}}{(i-1)!} \\
    &= \lambda e^{- \lambda} \sum_{i=0}^{+ \infty} \frac{\lambda^{i}}{i!} \\
    &= \lambda e^{- \lambda} e^\lambda \\
    &= \lambda
  \end{align*}
\end{proposition}
% TODO organizzare in proposizioni e dimostrazioni
\begin{proposition}[Varianza di \( X \) con distribuzione di Poisson]
  \label{pro:varianza_distribuzione_di_poisson}
  \begin{align*}
    \pr(X^2) &= \sum_{i=0}^{+ \infty} i^2 \pr(X = i) \\
    &= \sum_{i=0}^{+ \infty} i^2 \frac{\lambda^i}{i!} e^{- \lambda} \\
    &= \sum_{i=0}^{+ \infty} [(i^2 - i) + i] \frac{\lambda^i}{i!} e^{- \lambda} \\
    &= e^{- \lambda} (\sum_{i=0}^{+ \infty} i(i - 1) \frac{\lambda^i}{i(i-1)(i-2)!} + \sum_{i=0}^{+ \infty} i \frac{\lambda^i}{i!}) \\
    &= e^{- \lambda} (\sum_{i=0}^{+ \infty} \frac{\lambda^i}{(i-2)!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 \sum_{i=2}^{+ \infty} \frac{\lambda^{i-2}}{(i-2)!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 \sum_{i=0}^{+ \infty} \frac{\lambda^i}{i!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 e^\lambda + \lambda e^\lambda) \\
    &= \lambda^2 + \lambda
  \end{align*}
  \begin{align*}
    \var(X) &= \pr(X^2) - \pr(X)^2 \\
    &= \lambda^2 + \lambda - \lambda^2 \\
    &= \lambda
  \end{align*}
\end{proposition}

% section distribuzione_di_poisson (end)

\section{Indipendenza di partizioni} % (fold)
% DOUBT anche se sul libro e sugli appunti è qui, non starebbe meglio nella sezione sulle partizioni?
\begin{definition}[Indipendenza di partizioni]
  \label{def:indipendenza_di_partizioni}
  Date due partizioni
  \[ \mathcal{H} = (H_1, \ldots, H_m) \text{ e } \mathcal{L} = (L_1, \ldots, L_n) \]
  \( \mathcal{H} \) e \( \mathcal{L} \) sono stocasticamente indipendenti se comunque prendo un evento della prima ed un evento della seconda
  \footnote{ovvero \( \forall i, j; ~ 1 \le i \le m, ~ 1 \le j \le n \)}
  \[ \pr(H_i L_j) = \pr(H_i) \pr(L_j) \]
\end{definition}

L'indipendenza di partizioni generalizza il caso degli eventi
\footnote{vedi definizione \ref{def:indipendenza_stocastica}},
perché ad un evento può corrispondere una partizione:
\begin{definition}[Indipendenza di eventi tramite partizioni]
  Dati due numeri aleatori \( X \) ed \( Y \) con
  \[ I(X) = \{ x_1, \ldots, x_m \}, ~ I(Y) = \{ y_1, \ldots, y_n \} \]
  definiamo gli eventi
  \[ H_i = (X = x_i), ~ L_j = (Y = y_i) \]
  e le partizioni
  \[ \mathcal{H} = (H_1, \ldots, H_m), ~ \mathcal{L} = (L_1, \ldots, L_n) \]
  \( X \) ed \( Y \) si dicono stocasticamente indipendenti se lo sono le partizioni \( \mathcal{H} \) ed \( \mathcal{L} \).
\end{definition}
% section indipendenza_di_partizioni (end)
