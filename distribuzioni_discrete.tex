%!TEX root = appunti.tex
%!TEX encoding = UTF-8 Unicode
\chapter{Distribuzioni discrete}
\begin{definition}[Distribuzione discreta]\label{def:distribuzione_discreta}
  Una distribuzione statistica le cui variabili possono avere solo valori discreti.

  Dunque, un numero aleatorio $X$ si dice con distribuzione discreta se la cardinalità di $I(X)$ è finita o numerabile.
\end{definition}
\begin{definition}[Distribuzione di probabilità]\label{def:distribuzione_di_probabilita}
  La funzione che descrive la probabilità che un certo valore si verifichi.
  \marginnote{La distribuzione di probabilità viene anche detta ``funzione di densità di probabilità''.}

  Se consideriamo $X$ una variabile aleatoria con distribuzione discreta, la sua distribuzione di probabilità sarà data da
  \[ \pr(X = x_i) = p(x_i) \text{ con } x_i \in I(X) \]
  dove
  \[ \sum_{x_i \in I(X)} \pr(X = x_i) = 1 \]
\end{definition}

\begin{definition}[Schema di Bernoulli]\label{def:schema_bernoulli}
  Una successione \( (E_i)_{i \in \mathbb{N}} \) di eventi stocasticamente indipendenti ed equiprobabili, ovvero tali per cui vale che
  \[ \pr(E_i) = p, ~ \forall i \in \mathbb{N} \]
\end{definition}

\section{Distribuzione binomiale} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_binomiale}
  \caption{Distribuzione binomiale} 
\end{figure*}

\begin{definition}[Distribuzione binomiale]
  \label{def:distribuzione_binomiale}
  La distribuzione discreta della probabilità di ottenere $k$ successi su $n$ prove di Bernoulli.
  \footnote{ovvero dove il risultato è positivo con probabilità $p$ e negativo con probabilità \( (1-p) \), vedi definizione \ref{def:schema_bernoulli}}
\end{definition}

Dato uno schema di Bernoulli \( (E_i)_{i \in \mathbb{N}} \) con \( \pr(E_i) = p \),
\[ S_n = (E_1 + \ldots + E_n) \]
è il numero di successi su $n$ prove dove, ovviamente,
\[ I(S_n) = \{0,1, \ldots, n\} \]

La distribuzione di probabilità dunque è, tramite i costituenti:
\[ \pr(S_n = k) = \sum_{Q \subset (S_n = k)} \pr(Q) \]
ovvero dobbiamo sommare tutte le probabilità dei costituenti del primo tipo dell'evento \( (S_n = k) \), come, ad esempio
\[ Q = E_1 \cdots E_k \tilde{E}_{k+1} \cdots \tilde{E}_n \]
che rappresenta l'evento in cui i $k$ successi si sono ottenuti con le prime $k$ prove.
Analogamente ogni altro costituente di \( (S_n = k) \) conterrà $k$ eventi che si sono verificati e \( n-k \) che non si sono verificati.
Siccome tutti gli eventi sono indipendenti ed equamente distribuiti, ogni costituente $Q$ ha la stessa probabilità, pari a
\[ \pr(Q) = p^k (1-p)^{n-k} \]

Dunque per avere \( \pr(S_n = k) \), basta contare i costituenti.
Essi sono uguali al numero di modi di scegliere i $k$ eventi che si verificano sugli $n$ totali. Si ottiene quindi
\[
  \pr(S_n = k) = \binom{n}{k} p^k (1-p)^{n-k} 
\]

Si dice dunque che \( S_n \) ha distribuzione binomiale \( \mathcal{B}(n, p) \) dove $n$ è il numero degli eventi e $p$ la probabilità di ognuno.

\newthought{Calcoliamo infine la previsione di \( S_n \)}:
\begin{align*}
  \pr(S_n) &= \pr(E_1 + \ldots + E_n) \\
  &= \sum_{i=1}^n \pr(E_i) \\
  &= np
\end{align*}

\newthought{e la sua varianza}:
\begin{align*}
  \var(S_n) &= \var(E_1 + \ldots + E_n) \\
  &= \sum_{i = 1}^n \var(E_i) \\
  &= \sum_{i = 1}^n \pr(E_i^2) - \pr(E_i)^2 \\
  &= \sum_{i = 1}^n \pr(E_i) - \pr(E_i)^2 \\
  &= \sum_{i = 1}^n p - p^2 \\
  &= \sum_{i = 1}^n p (1 - p) \\
  &= n p (1 - p)
\end{align*}

% TODO 'moda' della distribuzione

% section distribuzione_binomiale (end)

\section{Distribuzione ipergeometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_ipergeometrica}
  \caption{Distribuzione ipergeometrica} 
\end{figure*}

\begin{definition}[Distribuzione ipergeometrica]
  \label{def:distribuzione_ipergeometrica}
  La distribuzione discreta della probabilità di ottenere \( i \) successi su \( n \) campioni, date \( H \) possibilità di successo su \( N \) possibilità totali.
\end{definition}
Consideriamo \( H \) modi per una ``buona'' selezione ed \( N - H \) per una ``cattiva'' selezione, su un totale di \( N \) possibilità.
Prendiamo \( n \) campioni e sia
\[ E_i = (\text{abbiamo una ``buona'' selezione all'}i\text{-esimo campione.}) \]
Sia \( X \) il numero aleatorio che conta il numero di buone selezioni:
\[
  X = \sum_{i = 1}^n E_i
\]

La probabilità di \( i \) selezioni di successo allora è
\begin{align*}
  \pr(X = i) &= \frac{[\text{\# modi per }i\text{ successi}][\text{\# modi per }n - i\text{ fallimenti}]}{[\text{\# casi possibili}]} \\
  &= \frac{\displaystyle \binom{H}{i} \binom{N-H}{n-i}}{\displaystyle \binom{N}{n}}
\end{align*}

Si dice dunque che \( X \) possiede distribuzione ipergeometrica.

\newthought{La probabilità dell'evento \( E_i \)} è data da:
\begin{align*}
  \pr(E_i) &= \frac{\text{\# casi favorevoli}}{\text{\# casi possibili}} \\
  &= \frac{H D_{n-1}^{N-1}}{D_n^N} \\
  &= \frac{H (N-1)(N-2) \cdots (N-n+1)}{N(N-1)(N-2) \cdots (N-n+1)} \\ % DOUBT qualcosa non torna...
  &= \frac{H}{N}
\end{align*}
dove \( D_k^n \) è una disposizione semplice\footnote{vedi definizione \ref{def:disposizione_semplice}} di \( k \) elementi su \( n \) possibili.

\newthought{Dunque la previsione di \( X \) è}:
\begin{align*}
  \pr(X) &= \sum_{i=1}^n \pr(E_i) \\
  &= n \frac{H}{N}
\end{align*}

\newthought{E la sua varianza è}:
\begin{align*}
  \var(S_n) &= \var \left(\sum_{i = 1}^n E_i\right) \\
  &= \sum_{i = 1}^n \var(E_i) + \sum_{i,j ~ i \neq j} \cov(E_i, E_j) \\ % DOUBT non ho la più pallida idea del perché
  &= n \frac{H}{N} \left( 1 - \frac{H}{N} \right)
\end{align*}
% section distribuzione_ipergeometrica (end)

\section{Distribuzione congiunta e marginale} % (fold)
\begin{definition}[Distribuzione congiunta]
  \label{def:distribuzione_congiunta}
  La funzione che definisce la probabilità di eventi definiti in termini di due numeri aleatori \( X \) ed \( Y \):
  \[
    p(x,y) \equiv \pr(X = x, Y = y)
  \]
  dove:
  \[
    (x,y) \in I(X,Y)
  \]
\end{definition}
È possibile rappresentare l'insieme dei valori che può assumere la funzione tramite la matrice:
\[
  \begin{pmatrix}
    p(x_1, y_1) & \dots & p(x_1, y_n) \\
    \vdots & \ddots & \vdots \\
    p(x_m, y_1) & \dots & p(x_m, y_n)
  \end{pmatrix}
\]

Inoltre:
\[
  \sum_x \sum_y p(x,y) = 1
\]

\begin{definition}[Distribuzione marginale]
  \label{def:distribuzione_marginale}
  Dato un numero aleatorio \( X \) è la funzione
  \[
    p(x) \equiv \pr(X = x)
  \]

  Conoscendo la distribuzione congiunta possiamo determinare la marginale, perché
  \begin{align*}
    p_1(x) &= \pr(X = x) \\
    &= \sum_{j = 1}^n \pr(X = x, Y = y_j) \\
    &= \sum_{j = 1}^n p(x, y_j)
  \end{align*}
  o analogamente per \( y \)
  \begin{align*}
    p_2(y) &= \pr(Y = y) \\
    &= \sum_{i = 1}^m \pr(X = x_i, Y = y) \\
    &= \sum_{i = 1}^m p(x_i, y)
  \end{align*}
\end{definition}

\begin{definition}[Indipendenza stocastica tramite la distribuzioni marginale]
  Due numeri aleatori \( X \) ed \( Y \) sono stocasticamente indipendenti se
  \[
    \forall i,j ~~ p(x_i, y_j) = p_1(x_i) p_2(y_j)
  \]
\end{definition}
% TODO gli appunti finiscono qui, ma sul libro a questo punto c'è altra roba...

% section distribuzione_congiunta_e_marginale (end)

\section{Distribuzione geometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_geometrica}
  \caption{Distribuzione geometrica} 
\end{figure*}

\begin{definition}[Distribuzione geometrica]\label{def:distribuzione_geometrica}
  La distribuzione discreta della probabilità di ottenere il primo successo all'istante $i$ in una serie di prove.
\end{definition}

Dato uno schema di Bernoulli \( E_i \) ed un numero aleatorio \( T \) che rappresenta l'istante del primo successo in una serie di prove, ovvero \( T = \inf\{ n | E_n = 1 \} \).
\[
  I(T) = \mathbb{N} \setminus \{ 0 \}
\]
\[
  (T = i) = \tilde{E}_1 \cdots \tilde{E}_{i-1} E_i
\]

La distribuzione discreta di probabilità è
\begin{align*}
  \pr(T = i) &= \pr(\tilde{E}_1 \cdots \tilde{E}_{i-1} E_i) \\
  &= \pr(\tilde{E}_1) \cdots \pr(\tilde{E}_{i-1}) \pr(E_i) \\
  &= (1-p)^{i-1} p  
\end{align*}

Si dice che \( T \) ha distribuzione geometrica di parametro \( p \).
Utilizzando la somma della serie geometrica, si verifica che
\begin{align*}
  \sum_{i=1}^{+ \infty} \pr(T = i) &= \sum_{i=1}^{+ \infty} (1-p)^{i-1} p \\
  &= p \sum_{i=1}^{+ \infty} (1-p)^{i-1}  \\
  &= p \frac{1}{1-(1-p)} \\
  &= 1
\end{align*}

% DOUBT come si chiama questo teorema?
\marginnote{Per ottenere questi ultimi due risultati abbiamo usato la serie notevole
\begin{align*}
  \sum_{i=1}^{+ \infty} i x^{i-1} &= \sum_{i=1}^{+ \infty} \frac{d}{dx}[x^i] \\
  &= \frac{d}{dx} (\sum_{i=0}^{+ \infty} x^i) \\
  &= \frac{d}{dx} (\frac{1}{1-x}) \\
  &= \frac{1}{(1-x)^2}
\end{align*}}

\newthought{Possiamo dunque calcolare la previsione di \( T \)}:
\begin{align*}
  \pr(T) &= \sum_{i=1}^{+ \infty} i \pr(T = i) \\
  &= \sum_{i=1}^{+ \infty} i (i - p)^{i-1} p \\
  &= p \sum_{i=1}^{+ \infty} i (i - p)^{i-1} \\
  &= p \frac{1}{p^2} \\
  &= \frac{1}{p}
\end{align*}

% TODO dimostrare perché \pr(T^2) = \frac{2-p}{p^2}
\newthought{E, dato \( \pr(T^2) = \frac{2-p}{p^2} \), la sua varianza}:
\begin{align*}
  \var(T) &= \pr(T^2) - \pr(T)^2 \\
  &= \frac{2-p}{p^2} - \frac{1}{p^2} \\
  &= \frac{1-p}{p^2}
\end{align*}

% section distribuzione_geometrica (end)

\section{Distribuzione di Poisson} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_di_poisson}
  \caption{Distribuzione di Poisson} 
\end{figure*}

\begin{definition}[Distribuzione di Poisson]
  \label{def:distribuzione_di_poisson}
  La distribuzione discreta della probabilità di ottenere \( i \) successi in un intervallo di tempo fissato,
  se questi eventi si verificano con una frequenza media nota e indipendentemente dal tempo passato dall'ultimo evento.

  È uguale a
  \[
    Pois(\lambda) \equiv \pr(X = i) = \frac{\lambda^i}{i!} e^{- \lambda}
  \]
  dove \( \lambda \) è un numero reale positivo, pari al numero atteso di eventi che si verificano durante l'intervallo di tempo e \( I(X) = \mathbb{N} \).
\end{definition}

\newthought{La previsione di \( X \) è}:
\marginnote{Utilizziamo la serie notevole \[ \sum_{k=0}^{+ \infty} \frac{x^k}{k!} = e^x \] e il fatto che \[ \frac{i}{i!} = \frac{1}{(i-1)!} \]}
\begin{align*}
  \pr(X) &= \sum_{i=0}^{+ \infty} i \pr(X = i) \\
  &= \sum_{i=0}^{+ \infty} i \frac{\lambda^i}{i!} e^{- \lambda} \\
  &= e^{- \lambda} \sum_{i=0}^{+ \infty} \frac{\lambda^i}{(i-1)!} \\
  &= \lambda e^{- \lambda} \sum_{i=1}^{+ \infty} \frac{\lambda^{i-1}}{(i-1)!} \\
  &= \lambda e^{- \lambda} \sum_{i=0}^{+ \infty} \frac{\lambda^{i}}{i!} \\
  &= \lambda e^{- \lambda} e^\lambda \\
  &= \lambda
\end{align*}

\newthought{La varianza di \( X \) è}:
\begin{align*}
  \pr(X^2) &= \sum_{i=0}^{+ \infty} i^2 \pr(X = i) \\
  &= \sum_{i=0}^{+ \infty} i^2 \frac{\lambda^i}{i!} e^{- \lambda} \\
  &= \sum_{i=0}^{+ \infty} [(i^2 - i) + i] \frac{\lambda^i}{i!} e^{- \lambda} \\
  &= e^{- \lambda} (\sum_{i=0}^{+ \infty} i(i - 1) \frac{\lambda^i}{i!} + \sum_{i=0}^{+ \infty} i \frac{\lambda^i}{i!}) \\
  &= e^{- \lambda} (\sum_{i=0}^{+ \infty} \frac{1(i - 1)\lambda^i}{(i-1)!} + \lambda e^\lambda) \\
  &= e^{- \lambda} (\sum_{i=0}^{+ \infty} \frac{1\lambda^i}{((i-1)-1)!} + \lambda e^\lambda) \\
  &= e^{- \lambda} (\lambda^2 \sum_{i=2}^{+ \infty} \frac{\lambda^{i-2}}{(i-2)!} + \lambda e^\lambda) \\
  &= e^{- \lambda} (\lambda^2 \sum_{i=0}^{+ \infty} \frac{\lambda^i}{i!} + \lambda e^\lambda) \\
  &= e^{- \lambda} (\lambda^2 e^\lambda + \lambda e^\lambda) \\
  &= \lambda^2 + \lambda
\end{align*}
% section distribuzione_di_poisson (end)

\section{Indipendenza di partizioni} % (fold)
% DOUBT anche se sul libro e sugli appunti è qui, non starebbe meglio nella sezione sulle partizioni?
\begin{definition}[Indipendenza di partizioni]
  \label{def:indipendenza_di_partizioni}
  Date due partizioni
  \[
    \mathcal{H} = (H_1, \ldots, H_m) \text{ e } \mathcal{L} = (L_1, \ldots, L_n)
  \]
  \( \mathcal{H} \) e \( \mathcal{L} \) sono stocasticamente indipendenti se comunque prendo un evento della prima ed un evento della seconda
  \footnote{ovvero \( \forall i, j; ~ 1 \le i \le m, ~ 1 \le j \le n \)}
  \[
    \pr(H_i L_j) = \pr(H_i) \pr(L_j)
  \]
\end{definition}

L'indipendenza di partizioni generalizza il caso degli eventi
\footnote{vedi definizione \ref{def:indipendenza_stocastica}},
perché ad un evento può corrispondere una partizione:
\begin{definition}[Indipendenza di eventi tramite partizioni]
  Dati due numeri aleatori \( X \) ed \( Y \) con
  \[
    I(X) = \{ x_1, \ldots, x_m \}, ~ I(Y) = \{ y_1, \ldots, y_n \}
  \]
  definiamo gli eventi
  \[
    H_i = (X = x_i), ~ L_j = (Y = y_i)
  \]
  e le partizioni
  \[
    \mathcal{H} = (H_1, \ldots, H_m), ~ \mathcal{L} = (L_1, \ldots, L_n)
  \]
  \( X \) ed \( Y \) si dicono stocasticamente indipendenti se lo sono le partizioni \( \mathcal{H} \) ed \( \mathcal{L} \).
\end{definition}
% section indipendenza_di_partizioni (end)
