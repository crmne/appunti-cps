%!TEX root = appunti.tex
%!TEX encoding = UTF-8 Unicode
\chapter{Distribuzioni discrete}
\begin{definition}[Distribuzione discreta]\label{def:distribuzione_discreta}
  Una distribuzione statistica le cui variabili possono avere solo valori discreti.

  Dunque, un numero aleatorio \( X \) si dice con distribuzione discreta se la cardinalità di \( I(X) \) è finita o numerabile.
\end{definition}
\begin{definition}[Distribuzione di probabilità]\label{def:distribuzione_di_probabilita}
  La funzione che descrive la probabilità che un certo valore si verifichi.
  \marginnote{La distribuzione di probabilità viene anche detta ``funzione di densità di probabilità''.}

  Se consideriamo \( X \) una variabile aleatoria con distribuzione discreta, la sua distribuzione di probabilità sarà data da
  \[ \pr(X = x_i) = p(x_i) \text{ con } x_i \in I(X) \]
  dove
  \[ \sum_{x_i \in I(X)} \pr(X = x_i) = 1 \]
\end{definition}

\begin{definition}[Schema di Bernoulli]\label{def:schema_bernoulli}
  Una successione \( (E_i)_{i \in \mathbb{N}} \) di eventi stocasticamente indipendenti ed equiprobabili, ovvero tali per cui vale che
  \[ \pr(E_i) = p, ~ \forall i \in \mathbb{N} \]
\end{definition}

\section{Distribuzione binomiale} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_binomiale}
  \caption{Distribuzione binomiale}
\end{figure*}

\begin{definition}[Distribuzione binomiale]
  \label{def:distribuzione_binomiale}
  La distribuzione discreta di probabilità del numero di successi in una sequenza di \( n \) eventi indipendenti, dove ognuno di essi ha successo con probabilità \( p \).
  \footnote{e fallimento con probabilità \( (1-p) \). Questo tipo di esperimenti di successo/fallimento si chiamano prove di Bernoulli o schema di Bernoulli, vedi definizione \ref{def:schema_bernoulli}.}

  \[ \mathcal{B}(n, p) \equiv \pr(X = k) = \binom{n}{k} p^k (1-p)^{n-k} \]
\end{definition}

\begin{proof}
  Dato uno schema di Bernoulli \( (E_i)_{i \in \mathbb{N}} \) con \( \pr(E_i) = p \),
  \[ X = (E_1 + \ldots + E_n) \]
  è il numero di successi su \( n \) prove dove, ovviamente,
  \[ I(X) = \{0, \ldots, n\} \]

  La distribuzione di probabilità dunque è, tramite i costituenti:
  \[ \pr(X = k) = \sum_{Q \subset (X = k)} \pr(Q) \]
  ovvero dobbiamo sommare tutte le probabilità dei costituenti del primo tipo dell'evento \( (X = k) \), come, ad esempio
  \[ Q = E_1 \cdots E_k \tilde{E}_{k+1} \cdots \tilde{E}_n \]
  che rappresenta l'evento in cui i \( k \) successi si sono ottenuti con le prime \( k \) prove.
  Analogamente ogni altro costituente di \( (X = k) \) conterrà \( k \) eventi che si sono verificati e \( n-k \) che non si sono verificati.
  Siccome tutti gli eventi sono indipendenti ed equamente distribuiti, ogni costituente \( Q \) ha la stessa probabilità, pari a
  \[ \pr(Q) = p^k (1-p)^{n-k} \]

  Dunque per avere \( \pr(X = k) \), basta contare i costituenti.
  Essi sono uguali al numero di modi di scegliere i \( k \) eventi che si verificano sugli \( n \) totali. Si ottiene quindi
  \[ \pr(X = k) = \binom{n}{k} p^k (1-p)^{n-k} \]

  Si dice dunque che \( X \) ha distribuzione binomiale \( \mathcal{B}(n, p) \) dove \( n \) è il numero degli eventi e \( p \) la probabilità di ognuno.
\end{proof}

\begin{proposition}[Previsione di \( X \) con distribuzione binomiale]
  \marginnote{vedi definizione \ref{def:schema_bernoulli}}
  \begin{align*}
    \pr(X) &= \pr(E_1 + \ldots + E_n) \\
    &= \sum_{i=1}^n \pr(E_i) \\
    &= np
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di un evento di Bernoulli]
  \marginnote{\( \pr(E_i^2) = \pr(E_i) \) perché \( 0^2 = 0 \) e \( 1^2 = 1 \).}
  \begin{align*}
    \var(E_i) &= \pr(E_i^2) - \pr(E_i)^2 \\
    &= \pr(E_i) - \pr(E_i)^2 \\
    &= p - p^2 \\
    &= p (1 - p)
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di \( X \) con distribuzione binomiale]
  \begin{align*}
    \var(X) &= \var(E_1 + \ldots + E_n) \\
    &= \sum_{i = 1}^n \var(E_i) \\
    &= \sum_{i = 1}^n p (1 - p) \\
    &= n p (1 - p)
  \end{align*}
\end{proposition}

% TODO 'moda' della distribuzione

% section distribuzione_binomiale (end)

\section{Distribuzione ipergeometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_ipergeometrica}
  \caption{Distribuzione ipergeometrica}
\end{figure*}

\begin{definition}[Distribuzione ipergeometrica]
  \label{def:distribuzione_ipergeometrica}
  \marginnote{La distribuzione ipergeometrica è simile alla distribuzione binomiale, che però descrive il numero di successi per \( n \) eventi \emph{indipendenti}, vedi \ref{def:distribuzione_binomiale}.}
  La distribuzione discreta di probabilità che descrive il numero di successi in una sequenza di  \( n \) eventi dipendenti, date \( H \) possibilità di successo su \( N \) possibilità totali.

  \[ \mathcal{HG}(n, H, N) \equiv \pr(X = k) = \frac{\binom{H}{k} \binom{N-H}{n-k}}{\binom{N}{n}} \]
\end{definition}

% TODO vincoli

\begin{proof}
  Consideriamo \( H \) possibilità di successo ed \( N - H \) possibilità di fallimento, su un totale di \( N \).
  Facciamo \( n \) prove e sia
  \[ E_i = (\text{successo all'}i\text{-esima prova}) \]
  Sia \( X \) il numero aleatorio che conta il numero di successi:
  \[ X = \sum_{i = 1}^n E_i \]

  Allora la probabilità di avere \( k \) successi è
  \marginnote{Il numero di casi possibili equivale a tutti i modi di effettuare \( n \) selezioni su \( N \) possibilità totali senza ripetizione e senza tener conto dell'ordine, ovvero ad una combinazione semplice, vedi definizione \ref{def:combinazione_semplice}.

    Otteniamo analogamente i casi possibili, tenendo conto che per ottenere \( k \) successi dobbiamo ottenere \( n - k \) fallimenti.}
  \begin{align*}
    \pr(X = k) &= \frac{\text{\# casi favorevoli}}{\text{\# casi possibili}} \\
    &= \frac{(\text{\# modi per }k\text{ successi})(\text{\# modi per }n - k\text{ fallimenti})}{\text{\# casi possibili}} \\
    &= \frac{\binom{H}{k} \binom{N-H}{n-k}}{\binom{N}{n}}
  \end{align*}

  Si dice dunque che \( X \) possiede distribuzione ipergeometrica.
\end{proof}

\begin{proposition}[Previsione di \( X \) con distribuzione ipergeometrica]
  \begin{align*}
    \pr(X) &= \sum_{i=1}^n \pr(E_i) \\
    &= \sum_{i=1}^n \frac{H}{N} \\
    &= n \frac{H}{N}
  \end{align*}
\end{proposition}

\begin{proposition}[Varianza di \( X \) con distribuzione ipergeometrica]
  \begin{align*} % TODO semplificare sta bestia
    \var(X) &= \var(E_1 + \ldots + E_n) \\
    &= \sum_{i = 1}^n \var(E_i) + \sum_{i,j ~ i < j} \cov(E_i, E_j) \\ % DOUBT non ho la più pallida idea del perché
    &= n \frac{H}{N} \left( 1 - \frac{H}{N} \right) + D_2^n \frac{H}{N^2} \frac{H - N}{N - 1} \\
    &= n \frac{N - n}{N - 1} \frac{H}{N} (1 - \frac{H}{N})
  \end{align*}
\end{proposition}

% section distribuzione_ipergeometrica (end)

\section{Distribuzione congiunta e marginale} % (fold)
\begin{definition}[Distribuzione congiunta]
  \label{def:distribuzione_congiunta}
  La funzione che definisce la probabilità di eventi definiti in termini di due numeri aleatori \( X \) ed \( Y \):
  \[ p(x,y) \equiv \pr(X = x, Y = y) \]
  dove:
  \[ (x,y) \in I(X,Y) \]
\end{definition}
È possibile rappresentare l'insieme dei valori che può assumere la funzione tramite la matrice:
\[
\begin{pmatrix}
  p(x_1, y_1) & \dots & p(x_1, y_n) \\
  \vdots & \ddots & \vdots \\
  p(x_m, y_1) & \dots & p(x_m, y_n)
\end{pmatrix}
\]

Inoltre:
\[ \sum_x \sum_y p(x,y) = 1 \]

\begin{definition}[Distribuzione marginale]
  \label{def:distribuzione_marginale}
  Dato un numero aleatorio \( X \) è la funzione
  \[ p(x) \equiv \pr(X = x) \]

  Conoscendo la distribuzione congiunta possiamo determinare la marginale, perché
  \begin{align*}
    p_1(x) &= \pr(X = x) \\
    &= \sum_{j = 1}^n \pr(X = x, Y = y_j) \\
    &= \sum_{j = 1}^n p(x, y_j)
  \end{align*}
  o analogamente per \( y \)
  \begin{align*}
    p_2(y) &= \pr(Y = y) \\
    &= \sum_{i = 1}^m \pr(X = x_i, Y = y) \\
    &= \sum_{i = 1}^m p(x_i, y)
  \end{align*}
\end{definition}

\begin{definition}[Indipendenza stocastica tramite la distribuzioni marginale]
  Due numeri aleatori \( X \) ed \( Y \) sono stocasticamente indipendenti se
  \[ \forall i,j ~~ p(x_i, y_j) = p_1(x_i) p_2(y_j) \]
\end{definition}
% TODO gli appunti finiscono qui, ma sul libro a questo punto c'è altra roba...

% section distribuzione_congiunta_e_marginale (end)

\section{Distribuzione geometrica} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_geometrica}
  \caption{Distribuzione geometrica}
\end{figure*}

\begin{definition}[Distribuzione geometrica]
  \label{def:distribuzione_geometrica}
  La distribuzione discreta di probabilità che descrive l'istante nel quale si verifica il primo successo in una serie di prove, dove ogni prova ha la stessa probabilità \( p \).

  \[ \mathcal{G}(p) \equiv \pr(X = k) = (1-p)^{k-1} p \]
\end{definition}

\begin{proof}
  Dato uno schema di Bernoulli \( E_i \) ed un numero aleatorio \( X \) che rappresenta l'istante del primo successo in una serie di prove, ovvero \( X = \inf\{ n | E_n = 1 \} \).
  \marginnote{Includendo lo \( 0 \) nell'insieme dei valori possibili l'intera distribuzione è traslata di \( -1 \) sull'asse delle ascisse, in modo da avere il picco a \( 0 \).

  Dunque la funzione di densità di probabilità diventa
  \[ \mathcal{G}(p) \equiv \pr(X = k) = (1-p)^k p \]}
  \[ I(X) = \mathbb{N} \setminus \{ 0 \} \]
  \[ (X = k) = \tilde{E}_1 \cdots \tilde{E}_{k-1} E_k \]

  La distribuzione discreta di probabilità è
  \begin{align*}
    \pr(X = k) &= \pr(\tilde{E}_1 \cdots \tilde{E}_{k-1} E_k) \\
    &= \pr(\tilde{E}_1) \cdots \pr(\tilde{E}_{k-1}) \pr(E_k) \\
    &= (1-p)^{k-1} p
  \end{align*}

  Si dice dunque che \( X \) ha distribuzione geometrica di parametro \( p \).
\end{proof}

\begin{proposition}[Previsione di \( X \) con distribuzione geometrica]
  \[ \pr(X) = \frac{1}{p} \]
\end{proposition}

\begin{proof}
  Utilizzando la somma della serie geometrica, si verifica che
  \marginnote{Qui usiamo la serie notevole
    \begin{align*}
      \sum_{i=1}^{+ \infty} i x^{i-1} &= \sum_{i=1}^{+ \infty} \frac{d}{dx}[x^i] \\
      &= \frac{d}{dx} (\sum_{i=0}^{+ \infty} x^i) \\
      &= \frac{d}{dx} (\frac{1}{1-x}) \\
      &= \frac{1}{(1-x)^2}
    \end{align*}
  }
  \begin{align*}
    \sum_{k=1}^{+ \infty} \pr(X = k) &= \sum_{k=1}^{+ \infty} (1-p)^{k-1} p \\
    &= p \sum_{k=1}^{+ \infty} (1-p)^{k-1}  \\
    &= p \frac{1}{1-(1-p)} \\
    &= 1
  \end{align*}

  Possiamo dunque calcolare la previsione di \( X \):
  \begin{align*}
    \pr(X) &= \sum_{k=1}^{+ \infty} k \pr(X = k) \\ % DOUBT perché?
    &= \sum_{k=1}^{+ \infty} k (k - p)^{k-1} p \\
    &= p \sum_{k=1}^{+ \infty} k (k - p)^{k-1} \\
    &= p \frac{1}{p^2} \\
    &= \frac{1}{p}
  \end{align*}
\end{proof}

\begin{proposition}[Varianza di \( X \) con distribuzione geometrica]
  \[ \var(X) = \frac{1-p}{p^2} \]
\end{proposition}

\begin{proof}
  Dato che
  \[ \pr(X^2) = \frac{2-p}{p^2} \] % TODO dimostrare
  abbiamo
  \begin{align*}
    \var(X) &= \pr(X^2) - \pr(X)^2 \\
    &= \frac{2-p}{p^2} - \frac{1}{p^2} \\
    &= \frac{1-p}{p^2}
  \end{align*}
\end{proof}

% section distribuzione_geometrica (end)

\section{Distribuzione di Poisson} % (fold)
\begin{figure*}
  \includegraphics{distribuzione_di_poisson}
  \caption{Distribuzione di Poisson}
\end{figure*}

\begin{definition}[Distribuzione di Poisson]
  \label{def:distribuzione_di_poisson}
  La distribuzione discreta di probabilità che descrive la probabilità di una serie di eventi che si verificano in un determinato periodo di tempo, se questi eventi si verificano con una frequenza media \( \lambda \) nota e indipendentemente dal tempo passato dall'ultimo evento.

  È uguale a
  \[ \mathcal{P}(\lambda) \equiv \pr(X = k) = \frac{\lambda^k}{k!} e^{- \lambda} \]
  dove \( \lambda \) è un numero reale positivo, pari al numero atteso di eventi che si verificano durante l'intervallo di tempo e \( I(X) = \mathbb{N} \).
\end{definition}

\begin{proposition}[Previsione di \( X \) con distribuzione di Poisson]
  \label{pro:previsione_distribuzione_di_poisson}
  \[ \pr(X) = \lambda \]
\end{proposition}

\begin{proof}
  \marginnote{Utilizziamo la serie notevole \[ \sum_{k=0}^{+ \infty} \frac{x^k}{k!} = e^x \] e la definizione di fattoriale \[ i! = i(i-1)! \]}
  \begin{align*}
    \pr(X) &= \sum_{k=0}^{+ \infty} k \pr(X = k) \\
    &= \sum_{k=0}^{+ \infty} k \frac{\lambda^k}{k!} e^{- \lambda} \\
    &= e^{- \lambda} \sum_{k=0}^{+ \infty} \frac{\lambda^k}{(k-1)!} \\
    &= \lambda e^{- \lambda} \sum_{k=1}^{+ \infty} \frac{\lambda^{k-1}}{(k-1)!} \\
    &= \lambda e^{- \lambda} \sum_{k=0}^{+ \infty} \frac{\lambda^{k}}{k!} \\
    &= \lambda e^{- \lambda} e^\lambda \\
    &= \lambda
  \end{align*}
\end{proof}

\begin{proposition}[Varianza di \( X \) con distribuzione di Poisson]
  \label{pro:varianza_distribuzione_di_poisson}
  \[ \var(X) = \lambda \]
\end{proposition}

\begin{proof}
  Dato che
  \begin{align*}
    \pr(X^2) &= \sum_{k=0}^{+ \infty} k^2 \pr(X = k) \\
    &= \sum_{k=0}^{+ \infty} k^2 \frac{\lambda^k}{k!} e^{- \lambda} \\
    &= \sum_{k=0}^{+ \infty} [(k^2 - k) + k] \frac{\lambda^k}{k!} e^{- \lambda} \\
    &= e^{- \lambda} (\sum_{k=0}^{+ \infty} k(k - 1) \frac{\lambda^k}{k(k-1)(k-2)!} + \sum_{k=0}^{+ \infty} k \frac{\lambda^k}{k!}) \\
    &= e^{- \lambda} (\sum_{k=0}^{+ \infty} \frac{\lambda^k}{(k-2)!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 \sum_{k=2}^{+ \infty} \frac{\lambda^{k-2}}{(k-2)!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 \sum_{k=0}^{+ \infty} \frac{\lambda^k}{k!} + \lambda e^\lambda) \\
    &= e^{- \lambda} (\lambda^2 e^\lambda + \lambda e^\lambda) \\
    &= \lambda^2 + \lambda
  \end{align*}
  abbiamo
  \begin{align*}
    \var(X) &= \pr(X^2) - \pr(X)^2 \\
    &= \lambda^2 + \lambda - \lambda^2 \\
    &= \lambda
  \end{align*}
\end{proof}

% section distribuzione_di_poisson (end)

\section{Indipendenza di partizioni} % (fold)
% DOUBT anche se sul libro e sugli appunti è qui, non starebbe meglio nella sezione sulle partizioni?
\begin{definition}[Indipendenza di partizioni]
  \label{def:indipendenza_di_partizioni}
  Date due partizioni
  \[ \mathcal{H} = (H_1, \ldots, H_m) \text{ e } \mathcal{L} = (L_1, \ldots, L_n) \]
  \( \mathcal{H} \) e \( \mathcal{L} \) sono stocasticamente indipendenti se comunque prendo un evento della prima ed un evento della seconda
  \footnote{ovvero \( \forall i, j; ~ 1 \le i \le m, ~ 1 \le j \le n \)}
  \[ \pr(H_i L_j) = \pr(H_i) \pr(L_j) \]
\end{definition}

L'indipendenza di partizioni generalizza il caso degli eventi
\footnote{vedi definizione \ref{def:indipendenza_stocastica}},
perché ad un evento può corrispondere una partizione:
\begin{definition}[Indipendenza di eventi tramite partizioni]
  Dati due numeri aleatori \( X \) ed \( Y \) con
  \[ I(X) = \{ x_1, \ldots, x_m \}, ~ I(Y) = \{ y_1, \ldots, y_n \} \]
  definiamo gli eventi
  \[ H_i = (X = x_i), ~ L_j = (Y = y_i) \]
  e le partizioni
  \[ \mathcal{H} = (H_1, \ldots, H_m), ~ \mathcal{L} = (L_1, \ldots, L_n) \]
  \( X \) ed \( Y \) si dicono stocasticamente indipendenti se lo sono le partizioni \( \mathcal{H} \) ed \( \mathcal{L} \).
\end{definition}
% section indipendenza_di_partizioni (end)
